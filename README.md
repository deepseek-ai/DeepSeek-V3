<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->

<div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/" target="_blank" style="margin: 2px;">
    <img alt="Ana Sayfa" src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://chat.deepseek.com/" target="_blank" style="margin: 2px;">
    <img alt="Mesaj" src="https://img.shields.io/badge/ğŸ¤–%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://huggingface.co/deepseek-ai" target="_blank" style="margin: 2px;">
    <img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>

<div align="center" style="line-height: 1;">
  <a href="https://discord.gg/Tc7c45Zzu5" target="_blank" style="margin: 2px;">
    <img alt="Discord" src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true" target="_blank" style="margin: 2px;">
    <img alt="Wechat" src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://twitter.com/deepseek_ai" target="_blank" style="margin: 2px;">
    <img alt="Twitter Takip" src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>

<div align="center" style="line-height: 1;">
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE" style="margin: 2px;">
    <img alt="Kod LisansÄ±" src="https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53" style="display: inline-block; vertical-align: middle;"/>
  </a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL" style="margin: 2px;">
    <img alt="Model LisansÄ±" src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53" style="display: inline-block; vertical-align: middle;"/>
  </a>
</div>


<p align="center">
  <a href="DeepSeek_V3.pdf"><b>Makale BaÄŸlantÄ±sÄ±</b>ğŸ‘ï¸</a>
</p>

## Ä°Ã§indekiler

1. [GiriÅŸ](#1-giriÅŸ)  
2. [Model Ã–zeti](#2-model-Ã¶zeti)  
3. [Model Ä°ndirmeleri](#3-model-indirmeleri)  
4. [DeÄŸerlendirme SonuÃ§larÄ±](#4-deÄŸerlendirme-sonuÃ§larÄ±)  
5. [Sohbet Web Sitesi ve API Platformu](#5-sohbet-web-sitesi-ve-api-platformu)  
6. [Yerel Olarak NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r](#6-yerel-olarak-nasÄ±l-Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r)  
7. [Lisans](#7-lisans)  
8. [AtÄ±f](#8-atÄ±f)  
9. [Ä°letiÅŸim](#9-iletiÅŸim)  


## 1. GiriÅŸ

DeepSeek-V3'Ã¼ sunuyoruz: 671 milyar toplam parametreye sahip gÃ¼Ã§lÃ¼ bir Mixture-of-Experts (MoE) dil modeli ve her bir token iÃ§in 37 milyar parametre etkinleÅŸtiriliyor.  
Verimli Ã§Ä±karÄ±m ve maliyet aÃ§Ä±sÄ±ndan etkili bir eÄŸitim saÄŸlamak amacÄ±yla DeepSeek-V3, Multi-head Latent Attention (MLA) ve DeepSeekMoE mimarilerini benimser; bu yaklaÅŸÄ±mlar DeepSeek-V2'de kapsamlÄ± ÅŸekilde doÄŸrulanmÄ±ÅŸtÄ±r.  
Bunun yanÄ± sÄ±ra, DeepSeek-V3, yÃ¼k dengeleme iÃ§in yardÄ±mcÄ± kayÄ±psÄ±z (auxiliary-loss-free) bir strateji geliÅŸtirerek Ã¶ncÃ¼lÃ¼k eder ve daha gÃ¼Ã§lÃ¼ performans iÃ§in Ã§oklu token tahminine dayalÄ± bir eÄŸitim hedefi belirler.  

DeepSeek-V3, 14.8 trilyon Ã§eÅŸitlendirilmiÅŸ ve yÃ¼ksek kaliteli token Ã¼zerinde Ã¶n eÄŸitimden geÃ§irilmiÅŸ olup, ardÄ±ndan Denetimli Ä°nce Ayar (Supervised Fine-Tuning) ve Takviyeli Ã–ÄŸrenme (Reinforcement Learning) aÅŸamalarÄ±ndan geÃ§irilerek yetenekleri tam anlamÄ±yla optimize edilmiÅŸtir.  
KapsamlÄ± deÄŸerlendirmeler, DeepSeek-V3'Ã¼n diÄŸer aÃ§Ä±k kaynak modellerini geride bÄ±raktÄ±ÄŸÄ±nÄ± ve Ã¶nde gelen kapalÄ± kaynak modellerle karÅŸÄ±laÅŸtÄ±rÄ±labilir bir performans sergilediÄŸini gÃ¶stermektedir.  

ÃœstÃ¼n performansÄ±na raÄŸmen, DeepSeek-V3'Ã¼n tam eÄŸitimi yalnÄ±zca **2.788 milyon H800 GPU saati** gerektirmektedir.  
Buna ek olarak, eÄŸitim sÃ¼reci son derece kararlÄ±dÄ±r.  
TÃ¼m eÄŸitim sÃ¼reci boyunca **geri dÃ¶ndÃ¼rÃ¼lemeyen kayÄ±p artÄ±ÅŸlarÄ± yaÅŸanmadÄ± ve herhangi bir geri alma (rollback) iÅŸlemi gerÃ§ekleÅŸtirilmedi**.  

<p align="center">
  <img width="80%" src="figures/benchmark.png">
</p>

## 2. Model Ã–zeti

---

**Mimari: YenilikÃ§i YÃ¼k Dengeleme Stratejisi ve EÄŸitim Hedefi**  

- DeepSeek-V2'nin verimli mimarisinin Ã¼zerine, **yardÄ±mcÄ± kayÄ±psÄ±z (auxiliary-loss-free) bir yÃ¼k dengeleme stratejisi** geliÅŸtirerek Ã¶ncÃ¼lÃ¼k ediyoruz.  
  Bu yaklaÅŸÄ±m, yÃ¼k dengelemenin teÅŸvik edilmesinden kaynaklanan **performans kaybÄ±nÄ± en aza indirir**.  
- **Ã‡oklu Token Tahmini (Multi-Token Prediction - MTP)** hedefini araÅŸtÄ±rÄ±yor ve bunun model performansÄ± aÃ§Ä±sÄ±ndan faydalÄ± olduÄŸunu kanÄ±tlÄ±yoruz.  
  AyrÄ±ca, bu yÃ¶ntem **Ã§Ä±karÄ±m sÃ¼recini hÄ±zlandÄ±rmak iÃ§in spekÃ¼latif kod Ã§Ã¶zmede (speculative decoding) de kullanÄ±labilir**.  

---
**Ã–n EÄŸitim: En Ãœst DÃ¼zey EÄŸitim VerimliliÄŸine DoÄŸru**  

- **FP8 karma hassasiyetli eÄŸitim Ã§erÃ§evesi** tasarladÄ±k ve **ilk kez** FP8 eÄŸitiminin **son derece bÃ¼yÃ¼k Ã¶lÃ§ekli bir modelde uygulanabilirliÄŸini ve etkinliÄŸini doÄŸruladÄ±k**.  
- **Algoritmalar, Ã§erÃ§eveler ve donanÄ±mlarÄ±n ortak tasarÄ±mÄ±** sayesinde, dÃ¼ÄŸÃ¼mler arasÄ± **MoE eÄŸitimindeki iletiÅŸim darboÄŸazÄ±nÄ±** aÅŸtÄ±k ve neredeyse **tam hesaplama-iletiÅŸim Ã¶rtÃ¼ÅŸmesi** saÄŸladÄ±k.  
  Bu, eÄŸitim verimliliÄŸimizi Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±rken **eÄŸitim maliyetlerini dÃ¼ÅŸÃ¼rerek** model boyutunu ek maliyet olmadan daha da Ã¶lÃ§eklendirmemize olanak tanÄ±r.  
- **Sadece 2.664 milyon H800 GPU saati** gibi ekonomik bir maliyetle, DeepSeek-V3'Ã¼n 14.8 trilyon token Ã¼zerinde Ã¶n eÄŸitimini tamamladÄ±k ve **mevcut en gÃ¼Ã§lÃ¼ aÃ§Ä±k kaynaklÄ± temel modeli Ã¼rettik**.  
  Ã–n eÄŸitim sonrasÄ± aÅŸamalar ise **yalnÄ±zca 0.1 milyon GPU saati gerektirir**.  

---

**Son EÄŸitim: DeepSeek-R1'den Bilgi AktarÄ±mÄ±**  

- **Uzun Zincirleme DÃ¼ÅŸÃ¼nme (Chain-of-Thought - CoT) modelinin** akÄ±l yÃ¼rÃ¼tme yeteneklerini, Ã¶zellikle **DeepSeek R1 serisi modellerinden biri Ã¼zerinden**, standart bÃ¼yÃ¼k dil modellerine (LLM) ve Ã¶zellikle DeepSeek-V3'e aktarmak iÃ§in yenilikÃ§i bir yÃ¶ntem geliÅŸtirdik.  
- **DoÄŸrulama ve yansÄ±tma (reflection) desenlerini** R1'den DeepSeek-V3'e **ÅŸÄ±k bir ÅŸekilde entegre eden** bu sÃ¼reÃ§, modelin **akÄ±l yÃ¼rÃ¼tme performansÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±rken**, **Ã§Ä±ktÄ± stilini ve uzunluÄŸunu da kontrol altÄ±nda tutmamÄ±za** olanak tanÄ±r.  

---


## 3. Model Ä°ndirmeleri

<div align="center">

| **Model** | **#Toplam Parametreler** | **#Etkin Parametreler** | **BaÄŸlam uzunluÄŸu** | **Ä°ndirme** |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | [ğŸ¤— Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-V3-Base)   |
| DeepSeek-V3   | 671B | 37B |  128K   | [ğŸ¤— Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-V3)   |

</div>

> [!NOTE]  
> **Hugging Face Ã¼zerindeki DeepSeek-V3 modellerinin toplam boyutu 685B'dir.**  
> Bu, **671B Ana Model aÄŸÄ±rlÄ±klarÄ±nÄ±** ve **14B Ã‡oklu Token Tahmini (MTP) ModÃ¼lÃ¼ aÄŸÄ±rlÄ±klarÄ±nÄ±** iÃ§erir.  

**Optimum performans ve esneklik saÄŸlamak** iÃ§in aÃ§Ä±k kaynak topluluklarÄ± ve donanÄ±m saÄŸlayÄ±cÄ±larÄ±yla iÅŸ birliÄŸi yaparak **modeli yerel olarak Ã§alÄ±ÅŸtÄ±rmak iÃ§in Ã§eÅŸitli yÃ¶ntemler sunduk**.  
AdÄ±m adÄ±m rehberlik iÃ§in **BÃ¶lÃ¼m 6: [NasÄ±l Yerel Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r](#6-how-to-run-locally)** kÄ±smÄ±na gÃ¶z atabilirsiniz.  

**Daha derin teknik ayrÄ±ntÄ±larla ilgilenen geliÅŸtiriciler iÃ§in**,  
**Ana Model aÄŸÄ±rlÄ±klarÄ± ve Ã‡oklu Token Tahmini (MTP) ModÃ¼lleri hakkÄ±nda detaylÄ± bilgileri** iÃ§eren  
[README_WEIGHTS.md](./README_WEIGHTS.md) dosyasÄ±nÄ± incelemenizi Ã¶neririz.  

LÃ¼tfen unutmayÄ±n: **MTP desteÄŸi ÅŸu anda topluluk tarafÄ±ndan aktif olarak geliÅŸtirilmektedir**.  
**KatkÄ±larÄ±nÄ±zÄ± ve geri bildirimlerinizi memnuniyetle karÅŸÄ±lÄ±yoruz!**  

---

## 4. DeÄŸerlendirme SonuÃ§larÄ±  
### Temel Model  
#### Standart KÄ±yaslamalar  


<div align="center">


|  | Performans DeÄŸerlendirmesi (Metrik) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | Architecture | - | MoE | Dense | Dense | MoE |
| | # Activated Params | - | 21B | 72B | 405B | 37B |
| | # Total Params | - | 236B | 72B | 405B | 671B |
| English | Pile-test (BPB) | - | 0.606 | 0.638 | **0.542** | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | **87.5** |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | **87.1** |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | **86.2** |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | **64.4** |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | **89.0** |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | **98.9** |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | **95.3** | **95.3** |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | **89.2** | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | **85.9** | 84.7 |
| | WinoGrande (Acc.) | 5-shot | **86.3** | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | **74.2** | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | **56.8** | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | 82.7 | **82.9** |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | **41.5** | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | **79.6** |
| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | **65.2** |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | **75.4** |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | **19.4** |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | **67.3** |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | **69.8** |
| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | **89.3** |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | **61.6** |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | **79.8** |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | **90.7** |
| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | **83.0** | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | **90.1** |
| | CMMLU (Acc.) | 5-shot | 84.0 | **89.5** | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | **77.4** | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | **79.7** | 78.6 |
| | CCPM (Acc.) | 0-shot | **93.0** | 88.5 | 78.6 | 92.0 |
| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | **79.4** |

</div>

> [!NOTE]  
> **En iyi sonuÃ§lar kalÄ±n olarak gÃ¶sterilmiÅŸtir.**  
> **AralarÄ±ndaki fark 0.3'Ã¼ geÃ§meyen skorlar aynÄ± seviyede kabul edilir.**  
> **DeepSeek-V3, Ã¶zellikle matematik ve kodlama gÃ¶revlerinde olmak Ã¼zere, Ã§oÄŸu kÄ±yaslamada en iyi performansÄ± sergilemektedir.**  
> **Daha fazla deÄŸerlendirme detayÄ± iÃ§in lÃ¼tfen makalemize gÃ¶z atÄ±n.**  

#### BaÄŸlam penceresi
<p align="center">
  <img width="80%" src="figures/niah.png">
</p>

**"Needle In A Haystack" (NIAH) testlerindeki deÄŸerlendirme sonuÃ§larÄ±.**  
DeepSeek-V3, **128K** baÄŸlam penceresine kadar tÃ¼m uzunluklarda iyi performans gÃ¶stermektedir.  

### Sohbet Modeli  
#### Standart KÄ±yaslamalar (67B'den bÃ¼yÃ¼k modeller)  
<div align="center">

| | **Performans DeÄŸerlendirmesi (Metrik)** | **DeepSeek V2-0506** | **DeepSeek V2.5-0905** | **Qwen2.5 72B-Inst.** | **Llama3.1 405B-Inst.** | **Claude-3.5-Sonnet-1022** | **GPT-4o 0513** | **DeepSeek V3** |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |
| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |
| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |
| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | **88.6** | **88.3** | 87.2 | **88.5** |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | **88.9** | 88.0 | **89.1** |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | **78.0** | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | **91.6** |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | **86.5** | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | **65.0** | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | **38.2** | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | **80.5** | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | **48.7** |
| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | **82.6** |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | **40.5** |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | **37.6** |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | **51.6** |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | **50.8** | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | **84.2** | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | **49.6** |
| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | **39.2** |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | **90.2** |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | **43.2** |
| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | **91.4** | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | **86.5** |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | **64.8** |

</div>

> [!NOTE]  
> **TÃ¼m modeller, Ã§Ä±ktÄ± uzunluÄŸunu 8K ile sÄ±nÄ±rlayan bir yapÄ±landÄ±rmada deÄŸerlendirilmiÅŸtir.**  
> **1000'den az Ã¶rnek iÃ§eren kÄ±yaslamalar, saÄŸlam nihai sonuÃ§lar elde etmek iÃ§in farklÄ± sÄ±caklÄ±k ayarlarÄ± kullanÄ±larak birden fazla kez test edilmiÅŸtir.**  
> **DeepSeek-V3, en iyi performans gÃ¶steren aÃ§Ä±k kaynak model olup, aynÄ± zamanda Ã¶ncÃ¼ kapalÄ± kaynak modellerle de rekabetÃ§i bir performans sergilemektedir.**  

#### AÃ§Ä±k UÃ§lu Ãœretim DeÄŸerlendirmesi  

<div align="center">



| Model | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | **85.5** | **70.0** |

</div>
> [!NOTE]  
> **Ä°ngilizce aÃ§Ä±k uÃ§lu konuÅŸma deÄŸerlendirmeleri.**  
> **AlpacaEval 2.0 iÃ§in, metrik olarak uzunluk kontrollÃ¼ kazanma oranÄ±nÄ± kullanÄ±yoruz.**  

## 5. Sohbet Web Sitesi & API Platformu  

DeepSeek-V3 ile sohbet etmek iÃ§in DeepSeekâ€™in resmi web sitesini ziyaret edebilirsiniz:  
[chat.deepseek.com](https://chat.deepseek.com/sign_in)  

AyrÄ±ca, OpenAI uyumlu APIâ€™mizi DeepSeek Platformunda saÄŸlÄ±yoruz:  
[platform.deepseek.com](https://platform.deepseek.com/)  

## 6. Yerel Olarak NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r  

DeepSeek-V3 aÅŸaÄŸÄ±daki donanÄ±m ve aÃ§Ä±k kaynak topluluk yazÄ±lÄ±mlarÄ± kullanÄ±larak yerel olarak daÄŸÄ±tÄ±labilir:  

1. **DeepSeek-Infer Demo**: FP8 ve BF16 Ã§Ä±karÄ±mÄ± iÃ§in basit ve hafif bir demo saÄŸlÄ±yoruz.  
2. **SGLang**: DeepSeek-V3 modelini hem BF16 hem de FP8 Ã§Ä±karÄ±m modlarÄ±nda tamamen destekler, Multi-Token Prediction ise [yakÄ±nda geliyor](https://github.com/sgl-project/sglang/issues/2591).  
3. **LMDeploy**: Yerel ve bulut daÄŸÄ±tÄ±mÄ± iÃ§in verimli FP8 ve BF16 Ã§Ä±karÄ±mÄ±na olanak tanÄ±r.  
4. **TensorRT-LLM**: Åu anda BF16 Ã§Ä±karÄ±mÄ±nÄ± ve INT4/8 nicemlemeyi destekler, FP8 desteÄŸi yakÄ±nda eklenecektir.  
5. **vLLM**: Tensor paralelliÄŸi ve ardÄ±ÅŸÄ±k iÅŸlem paralelliÄŸi iÃ§in DeepSeek-V3 modelini FP8 ve BF16 modlarÄ±nda destekler.  
6. **AMD GPU**: DeepSeek-V3 modelinin AMD GPUâ€™lar Ã¼zerinde SGLang aracÄ±lÄ±ÄŸÄ±yla BF16 ve FP8 modlarÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± saÄŸlar.  
7. **Huawei Ascend NPU**: DeepSeek-V3 modelinin Huawei Ascend cihazlarÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± destekler.  

FP8 eÄŸitimi Ã§erÃ§evemizde yerel olarak kullanÄ±ldÄ±ÄŸÄ± iÃ§in, yalnÄ±zca FP8 aÄŸÄ±rlÄ±klarÄ±nÄ± saÄŸlÄ±yoruz.  
Deneyleriniz iÃ§in BF16 aÄŸÄ±rlÄ±klarÄ±na ihtiyacÄ±nÄ±z varsa, saÄŸlanan dÃ¶nÃ¼ÅŸtÃ¼rme betiÄŸini kullanarak dÃ¶nÃ¼ÅŸÃ¼mÃ¼ gerÃ§ekleÅŸtirebilirsiniz.  

FP8 aÄŸÄ±rlÄ±klarÄ±nÄ± BF16'ya dÃ¶nÃ¼ÅŸtÃ¼rme Ã¶rneÄŸi:  

```shell
cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
```
> [!NOTE]  
> Hugging Face'in Transformers kÃ¼tÃ¼phanesi henÃ¼z doÄŸrudan desteklenmemektedir.  

### 6.1 DeepSeek-Infer Demo ile Ã‡Ä±karÄ±m (sadece Ã¶rnek)  

#### Sistem Gereksinimleri  

> [!NOTE]  
> **YalnÄ±zca Python 3.10 ile Linux desteklenmektedir.**  
> **Mac ve Windows desteklenmemektedir.**  

BaÄŸÄ±mlÄ±lÄ±klar:  
```pip-requirements
torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
```
#### Model AÄŸÄ±rlÄ±klarÄ± ve Demo Kodunun HazÄ±rlanmasÄ±  

Ã–ncelikle, DeepSeek-V3 GitHub deposunu klonlayÄ±n:
```shell
git clone https://github.com/deepseek-ai/DeepSeek-V3.git
```

`inference` klasÃ¶rÃ¼ne gidin ve `requirements.txt` dosyasÄ±nda listelenen baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin.  
En kolay yÃ¶ntem, `conda` veya `uv` gibi bir paket yÃ¶neticisi kullanarak yeni bir sanal ortam oluÅŸturmak ve baÄŸÄ±ml


```shell
cd DeepSeek-V3/inference
pip install -r requirements.txt
```

Model aÄŸÄ±rlÄ±klarÄ±nÄ± Hugging Face'den indirin ve `/path/to/DeepSeek-V3` klasÃ¶rÃ¼ne yerleÅŸtirin.

#### Model AÄŸÄ±rlÄ±klarÄ±nÄ± DÃ¶nÃ¼ÅŸtÃ¼rme

Hugging Face model aÄŸÄ±rlÄ±klarÄ±nÄ± belirli bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n:

```shell
python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
```

#### Ã‡alÄ±ÅŸtÄ±rma

ArdÄ±ndan DeepSeek-V3 ile sohbet edebilirsiniz:

```shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
```
Veya belirli bir dosyada toplu Ã§Ä±karÄ±m:

```shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
```

### 6.2 SGLang ile Ã‡Ä±karÄ±m (Tavsiye Edilir)

[SGLang](https://github.com/sgl-project/sglang) ÅŸu anda [MLA optimizasyonlarÄ±](https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations), [DP Attention](https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models), FP8 (W8A8), FP8 KV Ã–nbelleÄŸi ve Torch Compile'Ä± destekleyerek aÃ§Ä±k kaynaklÄ± Ã§erÃ§eveler arasÄ±nda en iyi gecikme sÃ¼resi ve verimlilik performansÄ±nÄ± sunmaktadÄ±r.

Ã–zellikle, [SGLang v0.4.1](https://github.com/sgl-project/sglang/releases/tag/v0.4.1), **NVIDIA ve AMD GPU'larda** DeepSeek-V3 Ã§alÄ±ÅŸtÄ±rmayÄ± tamamen destekleyerek onu son derece esnek ve saÄŸlam bir Ã§Ã¶zÃ¼m hÃ¢line getirmektedir.

SGLang ayrÄ±ca [Ã§oklu dÃ¼ÄŸÃ¼m tensÃ¶r paralelliÄŸini](https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208) destekleyerek, bu modeli aÄŸ baÄŸlantÄ±lÄ± birden fazla makinede Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

Ã‡oklu Token Tahmini (MTP) hÃ¢lÃ¢ geliÅŸtirme aÅŸamasÄ±nda olup ilerlemeyi [optimizasyon planÄ±](https://github.com/sgl-project/sglang/issues/2591) Ã¼zerinden takip edebilirsiniz.

SGLang ekibi tarafÄ±ndan saÄŸlanan baÅŸlatma talimatlarÄ±na buradan ulaÅŸabilirsiniz:  
[ğŸ”— SGLang DeepSeek-V3 Ã‡Ä±karÄ±m TalimatlarÄ±](https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3)

---

### 6.3 LMDeploy ile Ã‡Ä±karÄ±m (Tavsiye Edilir)

[LMDeploy](https://github.com/InternLM/lmdeploy), bÃ¼yÃ¼k dil modelleri iÃ§in esnek ve yÃ¼ksek performanslÄ± bir Ã§Ä±karÄ±m ve sunum Ã§erÃ§evesidir. DeepSeek-V3 desteÄŸi sunarak hem Ã§evrimdÄ±ÅŸÄ± iÅŸlem hattÄ± iÅŸleme hem de Ã§evrimiÃ§i daÄŸÄ±tÄ±m Ã¶zellikleri saÄŸlar ve PyTorch tabanlÄ± iÅŸ akÄ±ÅŸlarÄ±yla sorunsuz entegrasyon sunar.

DeepSeek-V3'Ã¼ LMDeploy ile Ã§alÄ±ÅŸtÄ±rma adÄ±mlarÄ± iÃ§in ayrÄ±ntÄ±lÄ± kÄ±lavuza buradan ulaÅŸabilirsiniz:  
[ğŸ”— LMDeploy Ã‡Ä±karÄ±m TalimatlarÄ±](https://github.com/InternLM/lmdeploy/issues/2960)

---

### 6.4 TRT-LLM ile Ã‡Ä±karÄ±m (Tavsiye Edilir)

[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM), DeepSeek-V3 modelini desteklemekte olup **BF16 ve INT4/INT8 aÄŸÄ±rlÄ±k hassasiyeti** seÃ§enekleri sunmaktadÄ±r. FP8 desteÄŸi ÅŸu anda geliÅŸtirilmekte olup yakÄ±nda yayÄ±nlanacaktÄ±r.

DeepSeek-V3 iÃ§in Ã¶zel olarak oluÅŸturulmuÅŸ TRT-LLM dalÄ±na buradan eriÅŸerek yeni Ã¶zellikleri doÄŸrudan deneyimleyebilirsiniz:  
[ğŸ”— TensorRT-LLM DeepSeek-V3 DesteÄŸi](https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3)

---

### 6.5 vLLM ile Ã‡Ä±karÄ±m (Tavsiye Edilir)

[vLLM](https://github.com/vllm-project/vllm) v0.6.6, **NVIDIA ve AMD GPU'larÄ±nda FP8 ve BF16 modlarÄ±nda** DeepSeek-V3 Ã§Ä±karÄ±mÄ±nÄ± destekler. Standart tekniklerin yanÄ± sÄ±ra, vLLM **boru hattÄ± paralelliÄŸi (pipeline parallelism)** de sunarak modeli birden fazla aÄŸa baÄŸlÄ± makinede Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

AyrÄ±ntÄ±lÄ± rehber iÃ§in buraya gÃ¶z atabilirsiniz:  
[ğŸ”— vLLM DaÄŸÄ±tÄ±lmÄ±ÅŸ Sunum TalimatlarÄ±](https://docs.vllm.ai/en/latest/serving/distributed_serving.html)

Ek olarak, geliÅŸtirme sÃ¼recini takip etmek iÃ§in ÅŸu baÄŸlantÄ±yÄ± inceleyebilirsiniz:  
[ğŸ”— vLLM GeliÅŸtirme PlanÄ±](https://github.com/vllm-project/vllm/issues/11539)

---

### 6.6 AMD GPU'lar iÃ§in Tavsiye Edilen Ã‡Ä±karÄ±m Ä°ÅŸlevselliÄŸi

AMD ekibiyle yapÄ±lan iÅŸ birliÄŸi sayesinde, DeepSeek-V3 modeli **FP8 ve BF16 hassasiyetiyle** AMD GPU'larda Ã§alÄ±ÅŸtÄ±rÄ±labilmektedir. Bu destek **SGLang** Ã¼zerinden saÄŸlanmaktadÄ±r.

AyrÄ±ntÄ±lÄ± rehber iÃ§in buraya gÃ¶z atabilirsiniz:  
[ğŸ”— SGLang AMD GPU TalimatlarÄ±](#63-inference-with-lmdeploy-recommended)

---

### 6.7 Huawei Ascend NPUâ€™lar iÃ§in Tavsiye Edilen Ã‡Ä±karÄ±m Ä°ÅŸlevselliÄŸi

Huawei Ascend topluluÄŸunun geliÅŸtirdiÄŸi [MindIE](https://www.hiascend.com/en/software/mindie) Ã§erÃ§evesi, **BF16 versiyonunda DeepSeek-V3** modelini baÅŸarÄ±yla adapte etmiÅŸtir.

Huawei Ascend NPU'larda Ã§alÄ±ÅŸtÄ±rma adÄ±mlarÄ± iÃ§in buraya gÃ¶z atabilirsiniz:  
[ğŸ”— MindIE DeepSeek-V3 TalimatlarÄ±](https://modelers.cn/models/MindIE/deepseekv3)

---

## 7. Lisans

Bu kod deposu [MIT LisansÄ±](LICENSE-CODE) altÄ±nda lisanslanmÄ±ÅŸtÄ±r.  
DeepSeek-V3 Base/Chat modellerinin kullanÄ±mÄ± [Model LisansÄ±](LICENSE-MODEL) hÃ¼kÃ¼mlerine tabidir.  
DeepSeek-V3 serisi (Base ve Chat dahil) ticari kullanÄ±mÄ± desteklemektedir.

---

## 8. AtÄ±f (Citation)

Bu Ã§alÄ±ÅŸmayÄ± aÅŸaÄŸÄ±daki gibi atÄ±fta bulunarak referans verebilirsiniz:

```
@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T. Wang and Tao Yun and Tian Pei and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and Y. K. Li and Y. Q. Wang and Y. X. Wei and Y. X. Zhu and Yang Zhang and Yanhong Xu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yu Wu and Yuan Ou and Yuchen Zhu and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yukun Zha and Yunfan Xiong and Yunxian Ma and Yuting Yan and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Z. F. Wu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhibin Gou and Zhicheng Ma and Zhigang Yan and Zhihong Shao and Zhipeng Xu and Zhiyu Wu and Zhongyu Zhang and Zhuoshu Li and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Ziyi Gao and Zizheng Pan},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
```

EÄŸer bu modeli veya iÃ§indeki teknikleri araÅŸtÄ±rmanÄ±zda kullanÄ±yorsanÄ±z, lÃ¼tfen yukarÄ±daki referansÄ± ekleyerek atÄ±fta bulunun.

---

## 9. Ä°letiÅŸim

Herhangi bir sorunuz varsa, lÃ¼tfen bir **issue** aÃ§Ä±n veya bizimle iletiÅŸime geÃ§in:  
ğŸ“§ [service@deepseek.com](service@deepseek.com)
